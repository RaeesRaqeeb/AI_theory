{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  LEARNING PANDAS : PROGRAMMING FOR AI : ENGR.MUHAMMAD UMER HAR😊😜N  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAKING A DATA FRAME FROM NUMPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1    2\n",
      "0    1    2    3\n",
      "1   11   22   33\n",
      "2  111  222  333\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "n_array = np.array([[1,2,3],[11,22,33],[111,222,333]])\n",
    "\n",
    "df = pd.DataFrame(n_array)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### HOW TO READ DIFFERENT FILES INTO DATA FRAME :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "URLError",
     "evalue": "<urlopen error [Errno 11001] getaddrinfo failed>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Umer Haroon\\.conda\\envs\\program_python\\lib\\urllib\\request.py:1354\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1353\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1354\u001b[0m     \u001b[43mh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1355\u001b[0m \u001b[43m              \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhas_header\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTransfer-encoding\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1356\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Umer Haroon\\.conda\\envs\\program_python\\lib\\http\\client.py:1256\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1255\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1256\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Umer Haroon\\.conda\\envs\\program_python\\lib\\http\\client.py:1302\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1301\u001b[0m     body \u001b[38;5;241m=\u001b[39m _encode(body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1302\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Umer Haroon\\.conda\\envs\\program_python\\lib\\http\\client.py:1251\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1250\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[1;32m-> 1251\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Umer Haroon\\.conda\\envs\\program_python\\lib\\http\\client.py:1011\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1010\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[1;32m-> 1011\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1013\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1014\u001b[0m \n\u001b[0;32m   1015\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Umer Haroon\\.conda\\envs\\program_python\\lib\\http\\client.py:951\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    950\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[1;32m--> 951\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    952\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Umer Haroon\\.conda\\envs\\program_python\\lib\\http\\client.py:1418\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1416\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnect to a host on a given (SSL) port.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1418\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tunnel_host:\n",
      "File \u001b[1;32mc:\\Users\\Umer Haroon\\.conda\\envs\\program_python\\lib\\http\\client.py:922\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    921\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Connect to the host and port specified in __init__.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 922\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock\u001b[38;5;241m.\u001b[39msetsockopt(socket\u001b[38;5;241m.\u001b[39mIPPROTO_TCP, socket\u001b[38;5;241m.\u001b[39mTCP_NODELAY, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Umer Haroon\\.conda\\envs\\program_python\\lib\\socket.py:787\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address)\u001b[0m\n\u001b[0;32m    786\u001b[0m err \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 787\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSOCK_STREAM\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    788\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
      "File \u001b[1;32mc:\\Users\\Umer Haroon\\.conda\\envs\\program_python\\lib\\socket.py:918\u001b[0m, in \u001b[0;36mgetaddrinfo\u001b[1;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[0;32m    917\u001b[0m addrlist \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 918\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_socket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    919\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
      "\u001b[1;31mgaierror\u001b[0m: [Errno 11001] getaddrinfo failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_json \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_json\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttps://jsonplaceholder.typicode.com/users\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_json\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m2\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\Umer Haroon\\.conda\\envs\\program_python\\lib\\site-packages\\pandas\\io\\json\\_json.py:760\u001b[0m, in \u001b[0;36mread_json\u001b[1;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options, dtype_backend, engine)\u001b[0m\n\u001b[0;32m    757\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_axes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m orient \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    758\u001b[0m     convert_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 760\u001b[0m json_reader \u001b[38;5;241m=\u001b[39m \u001b[43mJsonReader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    761\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    762\u001b[0m \u001b[43m    \u001b[49m\u001b[43morient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    763\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    764\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    765\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    766\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    767\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_default_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_default_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    768\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprecise_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprecise_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    769\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_unit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_unit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    772\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    773\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    774\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    775\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    776\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    777\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    778\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    779\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize:\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m json_reader\n",
      "File \u001b[1;32mc:\\Users\\Umer Haroon\\.conda\\envs\\program_python\\lib\\site-packages\\pandas\\io\\json\\_json.py:861\u001b[0m, in \u001b[0;36mJsonReader.__init__\u001b[1;34m(self, filepath_or_buffer, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, lines, chunksize, compression, nrows, storage_options, encoding_errors, dtype_backend, engine)\u001b[0m\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m filepath_or_buffer\n\u001b[0;32m    860\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mujson\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 861\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data_from_filepath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    862\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preprocess_data(data)\n",
      "File \u001b[1;32mc:\\Users\\Umer Haroon\\.conda\\envs\\program_python\\lib\\site-packages\\pandas\\io\\json\\_json.py:901\u001b[0m, in \u001b[0;36mJsonReader._get_data_from_filepath\u001b[1;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[0;32m    894\u001b[0m filepath_or_buffer \u001b[38;5;241m=\u001b[39m stringify_path(filepath_or_buffer)\n\u001b[0;32m    895\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    896\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filepath_or_buffer, \u001b[38;5;28mstr\u001b[39m)\n\u001b[0;32m    897\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m is_url(filepath_or_buffer)\n\u001b[0;32m    898\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m is_fsspec_url(filepath_or_buffer)\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m file_exists(filepath_or_buffer)\n\u001b[0;32m    900\u001b[0m ):\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    902\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    903\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    904\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    905\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    906\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    907\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    908\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    909\u001b[0m     filepath_or_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n\u001b[0;32m    910\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[0;32m    911\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(filepath_or_buffer, \u001b[38;5;28mstr\u001b[39m)\n\u001b[0;32m    912\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m filepath_or_buffer\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mendswith(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    915\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m file_exists(filepath_or_buffer)\n\u001b[0;32m    916\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\Umer Haroon\\.conda\\envs\\program_python\\lib\\site-packages\\pandas\\io\\common.py:716\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    713\u001b[0m     codecs\u001b[38;5;241m.\u001b[39mlookup_error(errors)\n\u001b[0;32m    715\u001b[0m \u001b[38;5;66;03m# open URLs\u001b[39;00m\n\u001b[1;32m--> 716\u001b[0m ioargs \u001b[38;5;241m=\u001b[39m \u001b[43m_get_filepath_or_buffer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    722\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    724\u001b[0m handle \u001b[38;5;241m=\u001b[39m ioargs\u001b[38;5;241m.\u001b[39mfilepath_or_buffer\n\u001b[0;32m    725\u001b[0m handles: \u001b[38;5;28mlist\u001b[39m[BaseBuffer]\n",
      "File \u001b[1;32mc:\\Users\\Umer Haroon\\.conda\\envs\\program_python\\lib\\site-packages\\pandas\\io\\common.py:368\u001b[0m, in \u001b[0;36m_get_filepath_or_buffer\u001b[1;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;66;03m# assuming storage_options is to be interpreted as headers\u001b[39;00m\n\u001b[0;32m    367\u001b[0m req_info \u001b[38;5;241m=\u001b[39m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mRequest(filepath_or_buffer, headers\u001b[38;5;241m=\u001b[39mstorage_options)\n\u001b[1;32m--> 368\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq_info\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m req:\n\u001b[0;32m    369\u001b[0m     content_encoding \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Encoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    370\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m content_encoding \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    371\u001b[0m         \u001b[38;5;66;03m# Override compression based on Content-Encoding header\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Umer Haroon\\.conda\\envs\\program_python\\lib\\site-packages\\pandas\\io\\common.py:270\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;124;03mLazy-import wrapper for stdlib urlopen, as that imports a big chunk of\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;124;03mthe stdlib.\u001b[39;00m\n\u001b[0;32m    267\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01murllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrequest\u001b[39;00m\n\u001b[1;32m--> 270\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Umer Haroon\\.conda\\envs\\program_python\\lib\\urllib\\request.py:222\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    221\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[1;32m--> 222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Umer Haroon\\.conda\\envs\\program_python\\lib\\urllib\\request.py:525\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    522\u001b[0m     req \u001b[38;5;241m=\u001b[39m meth(req)\n\u001b[0;32m    524\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murllib.Request\u001b[39m\u001b[38;5;124m'\u001b[39m, req\u001b[38;5;241m.\u001b[39mfull_url, req\u001b[38;5;241m.\u001b[39mdata, req\u001b[38;5;241m.\u001b[39mheaders, req\u001b[38;5;241m.\u001b[39mget_method())\n\u001b[1;32m--> 525\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[0;32m    528\u001b[0m meth_name \u001b[38;5;241m=\u001b[39m protocol\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_response\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Umer Haroon\\.conda\\envs\\program_python\\lib\\urllib\\request.py:542\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[1;34m(self, req, data)\u001b[0m\n\u001b[0;32m    539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m    541\u001b[0m protocol \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mtype\n\u001b[1;32m--> 542\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_open\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\n\u001b[0;32m    543\u001b[0m \u001b[43m                          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_open\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    544\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[0;32m    545\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\Umer Haroon\\.conda\\envs\\program_python\\lib\\urllib\\request.py:502\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[0;32m    501\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 502\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    503\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\Umer Haroon\\.conda\\envs\\program_python\\lib\\urllib\\request.py:1397\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m   1396\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[1;32m-> 1397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHTTPSConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1398\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Umer Haroon\\.conda\\envs\\program_python\\lib\\urllib\\request.py:1357\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1354\u001b[0m         h\u001b[38;5;241m.\u001b[39mrequest(req\u001b[38;5;241m.\u001b[39mget_method(), req\u001b[38;5;241m.\u001b[39mselector, req\u001b[38;5;241m.\u001b[39mdata, headers,\n\u001b[0;32m   1355\u001b[0m                   encode_chunked\u001b[38;5;241m=\u001b[39mreq\u001b[38;5;241m.\u001b[39mhas_header(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransfer-encoding\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m   1356\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[1;32m-> 1357\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n\u001b[0;32m   1358\u001b[0m     r \u001b[38;5;241m=\u001b[39m h\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m   1359\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[1;31mURLError\u001b[0m: <urlopen error [Errno 11001] getaddrinfo failed>"
     ]
    }
   ],
   "source": [
    "df_json = pd.read_json('https://jsonplaceholder.typicode.com/users')\n",
    "print(df_json.head(2))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       country  year         pop continent  lifeExp   gdpPercap\n",
      "1699  Zimbabwe  1987   9216418.0    Africa   62.351  706.157306\n",
      "1700  Zimbabwe  1992  10704340.0    Africa   60.377  693.420786\n",
      "1701  Zimbabwe  1997  11404948.0    Africa   46.809  792.449960\n",
      "1702  Zimbabwe  2002  11926563.0    Africa   39.989  672.038623\n",
      "1703  Zimbabwe  2007  12311143.0    Africa   43.487  469.709298\n"
     ]
    }
   ],
   "source": [
    "df_csv = pd.read_csv('https://raw.githubusercontent.com/plotly/datasets/master/gapminderDataFiveYear.csv')\n",
    "\n",
    "print(df_csv.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try out : df = pd.read_html('.....................')\n",
    "\n",
    "df = pd.read_sql('SELECT * FROM table_name', conn)  WILL TEACH THIS INSHALLAH\n",
    "\n",
    "df = pd.read_parquet('data.parquet')\n",
    "\n",
    "df = pd.read_feather('data.feather')\n",
    "\n",
    "df = pd.read_hdf('data.h5', 'table_name')\n",
    "\n",
    "df = pd.read_stata('data.dta')\n",
    "\n",
    "df = pd.read_sas('data.sas7bdat')\n",
    "\n",
    "df = pd.read_orc('data.orc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAKING DF FROM COPIED DATA , CLIPBOARD 🧷"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#will  work only work when some tabular data is copied from web source , doc or excel\n",
    "#e.g i copied table from https://www.islamicfinder.org/world/pakistan/\n",
    "copied_df= pd.read_clipboard()\n",
    "print(copied_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lets filter and get data of Pakistan only from above data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boolean Indexing:\n",
    "This method uses a condition inside square brackets to filter the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       country  year          pop continent  lifeExp    gdpPercap\n",
      "1164  Pakistan  1952   41346560.0      Asia   43.436   684.597144\n",
      "1165  Pakistan  1957   46679944.0      Asia   45.557   747.083529\n",
      "1166  Pakistan  1962   53100671.0      Asia   47.670   803.342742\n",
      "1167  Pakistan  1967   60641899.0      Asia   49.800   942.408259\n",
      "1168  Pakistan  1972   69325921.0      Asia   51.929  1049.938981\n",
      "1169  Pakistan  1977   78152686.0      Asia   54.043  1175.921193\n",
      "1170  Pakistan  1982   91462088.0      Asia   56.158  1443.429832\n",
      "1171  Pakistan  1987  105186881.0      Asia   58.245  1704.686583\n",
      "1172  Pakistan  1992  120065004.0      Asia   60.838  1971.829464\n",
      "1173  Pakistan  1997  135564834.0      Asia   61.818  2049.350521\n",
      "1174  Pakistan  2002  153403524.0      Asia   63.610  2092.712441\n",
      "1175  Pakistan  2007  169270617.0      Asia   65.483  2605.947580\n"
     ]
    }
   ],
   "source": [
    "Pakistan_data = df_csv[df_csv['country'] == 'Pakistan']\n",
    "print(Pakistan_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query Method:\n",
    "The query() method allows you to filter using a string expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       country  year          pop continent  lifeExp    gdpPercap\n",
      "1164  Pakistan  1952   41346560.0      Asia   43.436   684.597144\n",
      "1165  Pakistan  1957   46679944.0      Asia   45.557   747.083529\n",
      "1166  Pakistan  1962   53100671.0      Asia   47.670   803.342742\n",
      "1167  Pakistan  1967   60641899.0      Asia   49.800   942.408259\n",
      "1168  Pakistan  1972   69325921.0      Asia   51.929  1049.938981\n",
      "1169  Pakistan  1977   78152686.0      Asia   54.043  1175.921193\n",
      "1170  Pakistan  1982   91462088.0      Asia   56.158  1443.429832\n",
      "1171  Pakistan  1987  105186881.0      Asia   58.245  1704.686583\n",
      "1172  Pakistan  1992  120065004.0      Asia   60.838  1971.829464\n",
      "1173  Pakistan  1997  135564834.0      Asia   61.818  2049.350521\n",
      "1174  Pakistan  2002  153403524.0      Asia   63.610  2092.712441\n",
      "1175  Pakistan  2007  169270617.0      Asia   65.483  2605.947580\n"
     ]
    }
   ],
   "source": [
    "Pakistan_data_query = df_csv.query('country == \"Pakistan\"')\n",
    "print(Pakistan_data_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using loc:\n",
    "The loc accessor is used to access a group of rows and columns by labels or a boolean array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       country  year          pop continent  lifeExp    gdpPercap\n",
      "1164  Pakistan  1952   41346560.0      Asia   43.436   684.597144\n",
      "1165  Pakistan  1957   46679944.0      Asia   45.557   747.083529\n",
      "1166  Pakistan  1962   53100671.0      Asia   47.670   803.342742\n",
      "1167  Pakistan  1967   60641899.0      Asia   49.800   942.408259\n",
      "1168  Pakistan  1972   69325921.0      Asia   51.929  1049.938981\n",
      "1169  Pakistan  1977   78152686.0      Asia   54.043  1175.921193\n",
      "1170  Pakistan  1982   91462088.0      Asia   56.158  1443.429832\n",
      "1171  Pakistan  1987  105186881.0      Asia   58.245  1704.686583\n",
      "1172  Pakistan  1992  120065004.0      Asia   60.838  1971.829464\n",
      "1173  Pakistan  1997  135564834.0      Asia   61.818  2049.350521\n",
      "1174  Pakistan  2002  153403524.0      Asia   63.610  2092.712441\n",
      "1175  Pakistan  2007  169270617.0      Asia   65.483  2605.947580\n"
     ]
    }
   ],
   "source": [
    "Pakistan_data_loc = df_csv.loc[df_csv['country'] == 'Pakistan']\n",
    "print(Pakistan_data_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAKING SMALL DATA FRAME OUT OF LARGE DATA FRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'ai_batch_23.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# lets bring your data back :)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m df_temp \u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mai_batch_23.xlsx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# df data frame\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_temp)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#first make a specifc data frame with selected columns\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/excel/_base.py:478\u001b[0m, in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[1;32m    477\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 478\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    481\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    482\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    483\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/excel/_base.py:1496\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[1;32m   1494\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1495\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1496\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[43minspect_excel_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[1;32m   1498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1499\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1501\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1502\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1503\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/excel/_base.py:1371\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1368\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[1;32m   1369\u001b[0m     content_or_path \u001b[38;5;241m=\u001b[39m BytesIO(content_or_path)\n\u001b[0;32m-> 1371\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1372\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m   1373\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[1;32m   1374\u001b[0m     stream \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mhandle\n\u001b[1;32m   1375\u001b[0m     stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/common.py:868\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    860\u001b[0m             handle,\n\u001b[1;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    865\u001b[0m         )\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    869\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    871\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ai_batch_23.xlsx'"
     ]
    }
   ],
   "source": [
    "# lets bring your data back :)\n",
    "import pandas as pd\n",
    "df_temp =pd.read_excel(\"ai_batch_23.xlsx\") # df data frame\n",
    "print(df_temp)\n",
    "#first make a specifc data frame with selected columns\n",
    "df_ai = df_temp.iloc[:, [2, 6,17]]\n",
    "print(df_ai)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RENAME COLUMN NAME TO OOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Name  CGPA OOP\n",
      "0       Ahmed Lashari  3.10   A\n",
      "1        Nashwa Rahim  3.46   A\n",
      "2        Faakhir Abid  2.99  A-\n",
      "3     Muhammad Haseeb  3.42  A-\n",
      "4     Munazzah Fatima  2.95   I\n",
      "5         Shoaib Khan  2.62   I\n",
      "6        Hussain Shah  2.38  B-\n",
      "7         Hassan Shah  2.44  B-\n",
      "8       Umama Taimoor  3.51   I\n",
      "9        Muskan Nasir  2.33   I\n",
      "10     Muhammad Osama  1.29   -\n",
      "11       Fatiqa Munir  2.08   I\n",
      "12        Yawar Lodhi  1.94   C\n",
      "13         Sayil Raza  1.91  D+\n",
      "14        Daniyal Ali  1.60   -\n",
      "15        Fatima Khan  3.43  A-\n",
      "16           Eman Ali  2.64   I\n",
      "17      Haider Sheikh  1.20   -\n",
      "18       Shaheer Khan  2.31   I\n",
      "19     Ismail Mohmand  3.44  A+\n",
      "20        Mohid Zahid  1.54   -\n",
      "21         Naeem Khan  2.74  B-\n",
      "22      Jibran Khalil  2.52   A\n",
      "23          Mujeeb Ur  2.86   I\n",
      "24     Usama Sikandar  2.56   I\n",
      "25      Rayan Hussain  2.28  C+\n",
      "26     Muhammad Awais  1.61   -\n",
      "27       Hamza Sajjad  2.13  C-\n",
      "28          Arsam Ali  3.10  C+\n",
      "29    Muhammad Tayyab  2.52   I\n",
      "30          Aamir Ali  1.25   -\n",
      "31         Hamid Khan  1.56   -\n",
      "32     Muhammad Abbas  2.05   I\n",
      "33          Ali Irfan  2.15   I\n",
      "34        Maryam Amin  2.05  C+\n",
      "35       Sohail Ahmad  2.43   I\n",
      "36  Muhammad Abdullah  1.97   -\n",
      "37      Mehtab Hashmi  1.34   I\n",
      "38     Ghulam Murtaza  2.07   D\n",
      "39        Bilal Ahmad  3.29  B-\n",
      "40            Saif Ur  2.73   I\n",
      "41             Raqeeb  3.51   A\n",
      "42          Ahmad Jan  2.32   B\n",
      "43          Asaf Khan  3.34  B+\n",
      "44       Talha Zaheer  0.00   I\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Umer Haroon\\AppData\\Local\\Temp\\ipykernel_2368\\4279560920.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ai.rename(columns={'Object Oriented Programming-CS1004': 'OOP'}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df_ai.rename(columns={'Object Oriented Programming-CS1004': 'OOP'}, inplace=True)\n",
    "print(df_ai)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span color=\"green\">How to rename all columns at once ?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### how to replace a value with some other value in column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Name  CGPA      OOP\n",
      "0       Ahmed Lashari  3.10        A\n",
      "1        Nashwa Rahim  3.46        A\n",
      "2        Faakhir Abid  2.99       A-\n",
      "3     Muhammad Haseeb  3.42       A-\n",
      "4     Munazzah Fatima  2.95  pending\n",
      "5         Shoaib Khan  2.62  pending\n",
      "6        Hussain Shah  2.38       B-\n",
      "7         Hassan Shah  2.44       B-\n",
      "8       Umama Taimoor  3.51  pending\n",
      "9        Muskan Nasir  2.33  pending\n",
      "10     Muhammad Osama  1.29        -\n",
      "11       Fatiqa Munir  2.08  pending\n",
      "12        Yawar Lodhi  1.94        C\n",
      "13         Sayil Raza  1.91       D+\n",
      "14        Daniyal Ali  1.60        -\n",
      "15        Fatima Khan  3.43       A-\n",
      "16           Eman Ali  2.64  pending\n",
      "17      Haider Sheikh  1.20        -\n",
      "18       Shaheer Khan  2.31  pending\n",
      "19     Ismail Mohmand  3.44       A+\n",
      "20        Mohid Zahid  1.54        -\n",
      "21         Naeem Khan  2.74       B-\n",
      "22      Jibran Khalil  2.52        A\n",
      "23          Mujeeb Ur  2.86  pending\n",
      "24     Usama Sikandar  2.56  pending\n",
      "25      Rayan Hussain  2.28       C+\n",
      "26     Muhammad Awais  1.61        -\n",
      "27       Hamza Sajjad  2.13       C-\n",
      "28          Arsam Ali  3.10       C+\n",
      "29    Muhammad Tayyab  2.52  pending\n",
      "30          Aamir Ali  1.25        -\n",
      "31         Hamid Khan  1.56        -\n",
      "32     Muhammad Abbas  2.05  pending\n",
      "33          Ali Irfan  2.15  pending\n",
      "34        Maryam Amin  2.05       C+\n",
      "35       Sohail Ahmad  2.43  pending\n",
      "36  Muhammad Abdullah  1.97        -\n",
      "37      Mehtab Hashmi  1.34  pending\n",
      "38     Ghulam Murtaza  2.07        D\n",
      "39        Bilal Ahmad  3.29       B-\n",
      "40            Saif Ur  2.73  pending\n",
      "41             Raqeeb  3.51        A\n",
      "42          Ahmad Jan  2.32        B\n",
      "43          Asaf Khan  3.34       B+\n",
      "44       Talha Zaheer  0.00  pending\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Umer Haroon\\AppData\\Local\\Temp\\ipykernel_2368\\3547983048.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ai['OOP'] = df_ai['OOP'].replace('I', 'pending')\n"
     ]
    }
   ],
   "source": [
    "#lets replace I from OOP column to pending\n",
    "#df_ai.loc[df_ai['OOP'] == 'I', 'OOP'] = 'pending'\n",
    "#print(df_ai)\n",
    "\n",
    "df_ai['OOP'] = df_ai['OOP'].replace('I', 'pending')\n",
    "print(df_ai)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### changing case of columns name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 name  cgpa      oop\n",
      "0       Ahmed Lashari  3.10        A\n",
      "1        Nashwa Rahim  3.46        A\n",
      "2        Faakhir Abid  2.99       A-\n",
      "3     Muhammad Haseeb  3.42       A-\n",
      "4     Munazzah Fatima  2.95  pending\n",
      "5         Shoaib Khan  2.62  pending\n",
      "6        Hussain Shah  2.38       B-\n",
      "7         Hassan Shah  2.44       B-\n",
      "8       Umama Taimoor  3.51  pending\n",
      "9        Muskan Nasir  2.33  pending\n",
      "10     Muhammad Osama  1.29        -\n",
      "11       Fatiqa Munir  2.08  pending\n",
      "12        Yawar Lodhi  1.94        C\n",
      "13         Sayil Raza  1.91       D+\n",
      "14        Daniyal Ali  1.60        -\n",
      "15        Fatima Khan  3.43       A-\n",
      "16           Eman Ali  2.64  pending\n",
      "17      Haider Sheikh  1.20        -\n",
      "18       Shaheer Khan  2.31  pending\n",
      "19     Ismail Mohmand  3.44       A+\n",
      "20        Mohid Zahid  1.54        -\n",
      "21         Naeem Khan  2.74       B-\n",
      "22      Jibran Khalil  2.52        A\n",
      "23          Mujeeb Ur  2.86  pending\n",
      "24     Usama Sikandar  2.56  pending\n",
      "25      Rayan Hussain  2.28       C+\n",
      "26     Muhammad Awais  1.61        -\n",
      "27       Hamza Sajjad  2.13       C-\n",
      "28          Arsam Ali  3.10       C+\n",
      "29    Muhammad Tayyab  2.52  pending\n",
      "30          Aamir Ali  1.25        -\n",
      "31         Hamid Khan  1.56        -\n",
      "32     Muhammad Abbas  2.05  pending\n",
      "33          Ali Irfan  2.15  pending\n",
      "34        Maryam Amin  2.05       C+\n",
      "35       Sohail Ahmad  2.43  pending\n",
      "36  Muhammad Abdullah  1.97        -\n",
      "37      Mehtab Hashmi  1.34  pending\n",
      "38     Ghulam Murtaza  2.07        D\n",
      "39        Bilal Ahmad  3.29       B-\n",
      "40            Saif Ur  2.73  pending\n",
      "41             Raqeeb  3.51        A\n",
      "42          Ahmad Jan  2.32        B\n",
      "43          Asaf Khan  3.34       B+\n",
      "44       Talha Zaheer  0.00  pending\n"
     ]
    }
   ],
   "source": [
    "df_ai.columns = df_ai.columns.str.lower()  # same goes for upper\n",
    "print(df_ai)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what does it do ? #  df_ai.columns.str.title()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### adding something to start of column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             pai_name  pai_cgpa  pai_oop\n",
      "0       Ahmed Lashari      3.10        A\n",
      "1        Nashwa Rahim      3.46        A\n",
      "2        Faakhir Abid      2.99       A-\n",
      "3     Muhammad Haseeb      3.42       A-\n",
      "4     Munazzah Fatima      2.95  pending\n",
      "5         Shoaib Khan      2.62  pending\n",
      "6        Hussain Shah      2.38       B-\n",
      "7         Hassan Shah      2.44       B-\n",
      "8       Umama Taimoor      3.51  pending\n",
      "9        Muskan Nasir      2.33  pending\n",
      "10     Muhammad Osama      1.29        -\n",
      "11       Fatiqa Munir      2.08  pending\n",
      "12        Yawar Lodhi      1.94        C\n",
      "13         Sayil Raza      1.91       D+\n",
      "14        Daniyal Ali      1.60        -\n",
      "15        Fatima Khan      3.43       A-\n",
      "16           Eman Ali      2.64  pending\n",
      "17      Haider Sheikh      1.20        -\n",
      "18       Shaheer Khan      2.31  pending\n",
      "19     Ismail Mohmand      3.44       A+\n",
      "20        Mohid Zahid      1.54        -\n",
      "21         Naeem Khan      2.74       B-\n",
      "22      Jibran Khalil      2.52        A\n",
      "23          Mujeeb Ur      2.86  pending\n",
      "24     Usama Sikandar      2.56  pending\n",
      "25      Rayan Hussain      2.28       C+\n",
      "26     Muhammad Awais      1.61        -\n",
      "27       Hamza Sajjad      2.13       C-\n",
      "28          Arsam Ali      3.10       C+\n",
      "29    Muhammad Tayyab      2.52  pending\n",
      "30          Aamir Ali      1.25        -\n",
      "31         Hamid Khan      1.56        -\n",
      "32     Muhammad Abbas      2.05  pending\n",
      "33          Ali Irfan      2.15  pending\n",
      "34        Maryam Amin      2.05       C+\n",
      "35       Sohail Ahmad      2.43  pending\n",
      "36  Muhammad Abdullah      1.97        -\n",
      "37      Mehtab Hashmi      1.34  pending\n",
      "38     Ghulam Murtaza      2.07        D\n",
      "39        Bilal Ahmad      3.29       B-\n",
      "40            Saif Ur      2.73  pending\n",
      "41             Raqeeb      3.51        A\n",
      "42          Ahmad Jan      2.32        B\n",
      "43          Asaf Khan      3.34       B+\n",
      "44       Talha Zaheer      0.00  pending\n"
     ]
    }
   ],
   "source": [
    "df_ai =df_ai.add_prefix('pai_')\n",
    "print(df_ai)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what will add_suffix do ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reversing rows in data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             pai_name  pai_cgpa  pai_oop\n",
      "44       Talha Zaheer      0.00  pending\n",
      "43          Asaf Khan      3.34       B+\n",
      "42          Ahmad Jan      2.32        B\n",
      "41             Raqeeb      3.51        A\n",
      "40            Saif Ur      2.73  pending\n",
      "39        Bilal Ahmad      3.29       B-\n",
      "38     Ghulam Murtaza      2.07        D\n",
      "37      Mehtab Hashmi      1.34  pending\n",
      "36  Muhammad Abdullah      1.97        -\n",
      "35       Sohail Ahmad      2.43  pending\n",
      "34        Maryam Amin      2.05       C+\n",
      "33          Ali Irfan      2.15  pending\n",
      "32     Muhammad Abbas      2.05  pending\n",
      "31         Hamid Khan      1.56        -\n",
      "30          Aamir Ali      1.25        -\n",
      "29    Muhammad Tayyab      2.52  pending\n",
      "28          Arsam Ali      3.10       C+\n",
      "27       Hamza Sajjad      2.13       C-\n",
      "26     Muhammad Awais      1.61        -\n",
      "25      Rayan Hussain      2.28       C+\n",
      "24     Usama Sikandar      2.56  pending\n",
      "23          Mujeeb Ur      2.86  pending\n",
      "22      Jibran Khalil      2.52        A\n",
      "21         Naeem Khan      2.74       B-\n",
      "20        Mohid Zahid      1.54        -\n",
      "19     Ismail Mohmand      3.44       A+\n",
      "18       Shaheer Khan      2.31  pending\n",
      "17      Haider Sheikh      1.20        -\n",
      "16           Eman Ali      2.64  pending\n",
      "15        Fatima Khan      3.43       A-\n",
      "14        Daniyal Ali      1.60        -\n",
      "13         Sayil Raza      1.91       D+\n",
      "12        Yawar Lodhi      1.94        C\n",
      "11       Fatiqa Munir      2.08  pending\n",
      "10     Muhammad Osama      1.29        -\n",
      "9        Muskan Nasir      2.33  pending\n",
      "8       Umama Taimoor      3.51  pending\n",
      "7         Hassan Shah      2.44       B-\n",
      "6        Hussain Shah      2.38       B-\n",
      "5         Shoaib Khan      2.62  pending\n",
      "4     Munazzah Fatima      2.95  pending\n",
      "3     Muhammad Haseeb      3.42       A-\n",
      "2        Faakhir Abid      2.99       A-\n",
      "1        Nashwa Rahim      3.46        A\n",
      "0       Ahmed Lashari      3.10        A\n"
     ]
    }
   ],
   "source": [
    "print(df_ai.iloc[::-1])  # Reverses the order of rows , not saving this time just viewing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red;font-family:Lucida Handwriting\">how can we reverse and also change index to zero ... ? </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### changing column order only for display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    pai_cgpa  pai_oop           pai_name\n",
      "0       3.10        A      Ahmed Lashari\n",
      "1       3.46        A       Nashwa Rahim\n",
      "2       2.99       A-       Faakhir Abid\n",
      "3       3.42       A-    Muhammad Haseeb\n",
      "4       2.95  pending    Munazzah Fatima\n",
      "5       2.62  pending        Shoaib Khan\n",
      "6       2.38       B-       Hussain Shah\n",
      "7       2.44       B-        Hassan Shah\n",
      "8       3.51  pending      Umama Taimoor\n",
      "9       2.33  pending       Muskan Nasir\n",
      "10      1.29        -     Muhammad Osama\n",
      "11      2.08  pending       Fatiqa Munir\n",
      "12      1.94        C        Yawar Lodhi\n",
      "13      1.91       D+         Sayil Raza\n",
      "14      1.60        -        Daniyal Ali\n",
      "15      3.43       A-        Fatima Khan\n",
      "16      2.64  pending           Eman Ali\n",
      "17      1.20        -      Haider Sheikh\n",
      "18      2.31  pending       Shaheer Khan\n",
      "19      3.44       A+     Ismail Mohmand\n",
      "20      1.54        -        Mohid Zahid\n",
      "21      2.74       B-         Naeem Khan\n",
      "22      2.52        A      Jibran Khalil\n",
      "23      2.86  pending          Mujeeb Ur\n",
      "24      2.56  pending     Usama Sikandar\n",
      "25      2.28       C+      Rayan Hussain\n",
      "26      1.61        -     Muhammad Awais\n",
      "27      2.13       C-       Hamza Sajjad\n",
      "28      3.10       C+          Arsam Ali\n",
      "29      2.52  pending    Muhammad Tayyab\n",
      "30      1.25        -          Aamir Ali\n",
      "31      1.56        -         Hamid Khan\n",
      "32      2.05  pending     Muhammad Abbas\n",
      "33      2.15  pending          Ali Irfan\n",
      "34      2.05       C+        Maryam Amin\n",
      "35      2.43  pending       Sohail Ahmad\n",
      "36      1.97        -  Muhammad Abdullah\n",
      "37      1.34  pending      Mehtab Hashmi\n",
      "38      2.07        D     Ghulam Murtaza\n",
      "39      3.29       B-        Bilal Ahmad\n",
      "40      2.73  pending            Saif Ur\n",
      "41      3.51        A             Raqeeb\n",
      "42      2.32        B          Ahmad Jan\n",
      "43      3.34       B+          Asaf Khan\n",
      "44      0.00  pending       Talha Zaheer\n"
     ]
    }
   ],
   "source": [
    "print(df_ai[['pai_cgpa','pai_oop','pai_name']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### chaging column order actually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    pai_oop  pai_cgpa           pai_name\n",
      "0         A      3.10      Ahmed Lashari\n",
      "1         A      3.46       Nashwa Rahim\n",
      "2        A-      2.99       Faakhir Abid\n",
      "3        A-      3.42    Muhammad Haseeb\n",
      "4   pending      2.95    Munazzah Fatima\n",
      "5   pending      2.62        Shoaib Khan\n",
      "6        B-      2.38       Hussain Shah\n",
      "7        B-      2.44        Hassan Shah\n",
      "8   pending      3.51      Umama Taimoor\n",
      "9   pending      2.33       Muskan Nasir\n",
      "10        -      1.29     Muhammad Osama\n",
      "11  pending      2.08       Fatiqa Munir\n",
      "12        C      1.94        Yawar Lodhi\n",
      "13       D+      1.91         Sayil Raza\n",
      "14        -      1.60        Daniyal Ali\n",
      "15       A-      3.43        Fatima Khan\n",
      "16  pending      2.64           Eman Ali\n",
      "17        -      1.20      Haider Sheikh\n",
      "18  pending      2.31       Shaheer Khan\n",
      "19       A+      3.44     Ismail Mohmand\n",
      "20        -      1.54        Mohid Zahid\n",
      "21       B-      2.74         Naeem Khan\n",
      "22        A      2.52      Jibran Khalil\n",
      "23  pending      2.86          Mujeeb Ur\n",
      "24  pending      2.56     Usama Sikandar\n",
      "25       C+      2.28      Rayan Hussain\n",
      "26        -      1.61     Muhammad Awais\n",
      "27       C-      2.13       Hamza Sajjad\n",
      "28       C+      3.10          Arsam Ali\n",
      "29  pending      2.52    Muhammad Tayyab\n",
      "30        -      1.25          Aamir Ali\n",
      "31        -      1.56         Hamid Khan\n",
      "32  pending      2.05     Muhammad Abbas\n",
      "33  pending      2.15          Ali Irfan\n",
      "34       C+      2.05        Maryam Amin\n",
      "35  pending      2.43       Sohail Ahmad\n",
      "36        -      1.97  Muhammad Abdullah\n",
      "37  pending      1.34      Mehtab Hashmi\n",
      "38        D      2.07     Ghulam Murtaza\n",
      "39       B-      3.29        Bilal Ahmad\n",
      "40  pending      2.73            Saif Ur\n",
      "41        A      3.51             Raqeeb\n",
      "42        B      2.32          Ahmad Jan\n",
      "43       B+      3.34          Asaf Khan\n",
      "44  pending      0.00       Talha Zaheer\n"
     ]
    }
   ],
   "source": [
    "# Reverse using iloc\n",
    "df_reversed_iloc = df_ai.iloc[:, ::-1]\n",
    "print(df_reversed_iloc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### display only headings of a data frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['pai_name', 'pai_cgpa', 'pai_oop'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_ai.columns)  # not intended output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    pai_name\n",
      "1    pai_cgpa\n",
      "2     pai_oop\n"
     ]
    }
   ],
   "source": [
    "print(pd.Series(df_ai.columns).to_string()) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pai_name\n",
      "pai_cgpa\n",
      " pai_oop\n"
     ]
    }
   ],
   "source": [
    "print(pd.Series(df_ai.columns).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    pai_name\n",
      "1    pai_cgpa\n",
      "2     pai_oop\n"
     ]
    }
   ],
   "source": [
    "print(pd.Series(df_ai.columns).to_string(index=True),sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#in above code we didnt got what we wanted 😼 , figure out why 🙍‍♀️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pai_name, pai_cgpa, pai_oop\n"
     ]
    }
   ],
   "source": [
    "print(', '.join(df_ai.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SELECT COLUMNS BY TYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    pai_cgpa\n",
      "0       3.10\n",
      "1       3.46\n",
      "2       2.99\n",
      "3       3.42\n",
      "4       2.95\n",
      "5       2.62\n",
      "6       2.38\n",
      "7       2.44\n",
      "8       3.51\n",
      "9       2.33\n",
      "10      1.29\n",
      "11      2.08\n",
      "12      1.94\n",
      "13      1.91\n",
      "14      1.60\n",
      "15      3.43\n",
      "16      2.64\n",
      "17      1.20\n",
      "18      2.31\n",
      "19      3.44\n",
      "20      1.54\n",
      "21      2.74\n",
      "22      2.52\n",
      "23      2.86\n",
      "24      2.56\n",
      "25      2.28\n",
      "26      1.61\n",
      "27      2.13\n",
      "28      3.10\n",
      "29      2.52\n",
      "30      1.25\n",
      "31      1.56\n",
      "32      2.05\n",
      "33      2.15\n",
      "34      2.05\n",
      "35      2.43\n",
      "36      1.97\n",
      "37      1.34\n",
      "38      2.07\n",
      "39      3.29\n",
      "40      2.73\n",
      "41      3.51\n",
      "42      2.32\n",
      "43      3.34\n",
      "44      0.00\n"
     ]
    }
   ],
   "source": [
    "print(df_ai.select_dtypes(include='number'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44]\n"
     ]
    }
   ],
   "source": [
    "print(df_ai.select_dtypes(include='int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             pai_name  pai_oop\n",
      "0       Ahmed Lashari        A\n",
      "1        Nashwa Rahim        A\n",
      "2        Faakhir Abid       A-\n",
      "3     Muhammad Haseeb       A-\n",
      "4     Munazzah Fatima  pending\n",
      "5         Shoaib Khan  pending\n",
      "6        Hussain Shah       B-\n",
      "7         Hassan Shah       B-\n",
      "8       Umama Taimoor  pending\n",
      "9        Muskan Nasir  pending\n",
      "10     Muhammad Osama        -\n",
      "11       Fatiqa Munir  pending\n",
      "12        Yawar Lodhi        C\n",
      "13         Sayil Raza       D+\n",
      "14        Daniyal Ali        -\n",
      "15        Fatima Khan       A-\n",
      "16           Eman Ali  pending\n",
      "17      Haider Sheikh        -\n",
      "18       Shaheer Khan  pending\n",
      "19     Ismail Mohmand       A+\n",
      "20        Mohid Zahid        -\n",
      "21         Naeem Khan       B-\n",
      "22      Jibran Khalil        A\n",
      "23          Mujeeb Ur  pending\n",
      "24     Usama Sikandar  pending\n",
      "25      Rayan Hussain       C+\n",
      "26     Muhammad Awais        -\n",
      "27       Hamza Sajjad       C-\n",
      "28          Arsam Ali       C+\n",
      "29    Muhammad Tayyab  pending\n",
      "30          Aamir Ali        -\n",
      "31         Hamid Khan        -\n",
      "32     Muhammad Abbas  pending\n",
      "33          Ali Irfan  pending\n",
      "34        Maryam Amin       C+\n",
      "35       Sohail Ahmad  pending\n",
      "36  Muhammad Abdullah        -\n",
      "37      Mehtab Hashmi  pending\n",
      "38     Ghulam Murtaza        D\n",
      "39        Bilal Ahmad       B-\n",
      "40            Saif Ur  pending\n",
      "41             Raqeeb        A\n",
      "42          Ahmad Jan        B\n",
      "43          Asaf Khan       B+\n",
      "44       Talha Zaheer  pending\n"
     ]
    }
   ],
   "source": [
    "print(df_ai.select_dtypes(exclude='number'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pai_name</th>\n",
       "      <th>pai_oop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ahmed Lashari</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nashwa Rahim</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Faakhir Abid</td>\n",
       "      <td>A-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Muhammad Haseeb</td>\n",
       "      <td>A-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Munazzah Fatima</td>\n",
       "      <td>pending</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Shoaib Khan</td>\n",
       "      <td>pending</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hussain Shah</td>\n",
       "      <td>B-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hassan Shah</td>\n",
       "      <td>B-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Umama Taimoor</td>\n",
       "      <td>pending</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Muskan Nasir</td>\n",
       "      <td>pending</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Muhammad Osama</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Fatiqa Munir</td>\n",
       "      <td>pending</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Yawar Lodhi</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Sayil Raza</td>\n",
       "      <td>D+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Daniyal Ali</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Fatima Khan</td>\n",
       "      <td>A-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Eman Ali</td>\n",
       "      <td>pending</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Haider Sheikh</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Shaheer Khan</td>\n",
       "      <td>pending</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Ismail Mohmand</td>\n",
       "      <td>A+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Mohid Zahid</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Naeem Khan</td>\n",
       "      <td>B-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Jibran Khalil</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Mujeeb Ur</td>\n",
       "      <td>pending</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Usama Sikandar</td>\n",
       "      <td>pending</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Rayan Hussain</td>\n",
       "      <td>C+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Muhammad Awais</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Hamza Sajjad</td>\n",
       "      <td>C-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Arsam Ali</td>\n",
       "      <td>C+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Muhammad Tayyab</td>\n",
       "      <td>pending</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Aamir Ali</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Hamid Khan</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Muhammad Abbas</td>\n",
       "      <td>pending</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Ali Irfan</td>\n",
       "      <td>pending</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Maryam Amin</td>\n",
       "      <td>C+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Sohail Ahmad</td>\n",
       "      <td>pending</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Muhammad Abdullah</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Mehtab Hashmi</td>\n",
       "      <td>pending</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Ghulam Murtaza</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Bilal Ahmad</td>\n",
       "      <td>B-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Saif Ur</td>\n",
       "      <td>pending</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Raqeeb</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Ahmad Jan</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Asaf Khan</td>\n",
       "      <td>B+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Talha Zaheer</td>\n",
       "      <td>pending</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             pai_name  pai_oop\n",
       "0       Ahmed Lashari        A\n",
       "1        Nashwa Rahim        A\n",
       "2        Faakhir Abid       A-\n",
       "3     Muhammad Haseeb       A-\n",
       "4     Munazzah Fatima  pending\n",
       "5         Shoaib Khan  pending\n",
       "6        Hussain Shah       B-\n",
       "7         Hassan Shah       B-\n",
       "8       Umama Taimoor  pending\n",
       "9        Muskan Nasir  pending\n",
       "10     Muhammad Osama        -\n",
       "11       Fatiqa Munir  pending\n",
       "12        Yawar Lodhi        C\n",
       "13         Sayil Raza       D+\n",
       "14        Daniyal Ali        -\n",
       "15        Fatima Khan       A-\n",
       "16           Eman Ali  pending\n",
       "17      Haider Sheikh        -\n",
       "18       Shaheer Khan  pending\n",
       "19     Ismail Mohmand       A+\n",
       "20        Mohid Zahid        -\n",
       "21         Naeem Khan       B-\n",
       "22      Jibran Khalil        A\n",
       "23          Mujeeb Ur  pending\n",
       "24     Usama Sikandar  pending\n",
       "25      Rayan Hussain       C+\n",
       "26     Muhammad Awais        -\n",
       "27       Hamza Sajjad       C-\n",
       "28          Arsam Ali       C+\n",
       "29    Muhammad Tayyab  pending\n",
       "30          Aamir Ali        -\n",
       "31         Hamid Khan        -\n",
       "32     Muhammad Abbas  pending\n",
       "33          Ali Irfan  pending\n",
       "34        Maryam Amin       C+\n",
       "35       Sohail Ahmad  pending\n",
       "36  Muhammad Abdullah        -\n",
       "37      Mehtab Hashmi  pending\n",
       "38     Ghulam Murtaza        D\n",
       "39        Bilal Ahmad       B-\n",
       "40            Saif Ur  pending\n",
       "41             Raqeeb        A\n",
       "42          Ahmad Jan        B\n",
       "43          Asaf Khan       B+\n",
       "44       Talha Zaheer  pending"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ai.select_dtypes(include='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    pai_cgpa\n",
      "0       3.10\n",
      "1       3.46\n",
      "2       2.99\n",
      "3       3.42\n",
      "4       2.95\n",
      "5       2.62\n",
      "6       2.38\n",
      "7       2.44\n",
      "8       3.51\n",
      "9       2.33\n",
      "10      1.29\n",
      "11      2.08\n",
      "12      1.94\n",
      "13      1.91\n",
      "14      1.60\n",
      "15      3.43\n",
      "16      2.64\n",
      "17      1.20\n",
      "18      2.31\n",
      "19      3.44\n",
      "20      1.54\n",
      "21      2.74\n",
      "22      2.52\n",
      "23      2.86\n",
      "24      2.56\n",
      "25      2.28\n",
      "26      1.61\n",
      "27      2.13\n",
      "28      3.10\n",
      "29      2.52\n",
      "30      1.25\n",
      "31      1.56\n",
      "32      2.05\n",
      "33      2.15\n",
      "34      2.05\n",
      "35      2.43\n",
      "36      1.97\n",
      "37      1.34\n",
      "38      2.07\n",
      "39      3.29\n",
      "40      2.73\n",
      "41      3.51\n",
      "42      2.32\n",
      "43      3.34\n",
      "44      0.00\n"
     ]
    }
   ],
   "source": [
    "print(df_ai.select_dtypes(include=['int', 'float']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TYPE CASTING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* to understand this lets come with a different data frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Integers    Floats  Strings  More Floats\n",
      "0         3  4.869829        4     0.923095\n",
      "1         0  4.049693        3     0.396781\n",
      "2         1  2.903451        2     0.671409\n",
      "3         3  9.978000        3     0.855655\n",
      "4         4  6.982027        3     0.401307\n"
     ]
    }
   ],
   "source": [
    "new_df=pd.DataFrame({\n",
    "    'Integers': np.random.randint(5,size=5),\n",
    "    'Floats': np.random.uniform(1, 10, size=5),\n",
    "    'Strings': np.random.randint(5,size=5),\n",
    "    'More Floats': np.random.rand(5)  # Another column of random floats\n",
    "})\n",
    "\n",
    "print(new_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " lets check types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integers         int32\n",
      "Floats         float64\n",
      "Strings          int32\n",
      "More Floats    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(new_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so the name is string but in nature its not string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Integers    Floats Strings  More Floats\n",
      "0         3  4.869829     '4'     0.923095\n",
      "1         0  4.049693     '3'     0.396781\n",
      "2         1  2.903451     '2'     0.671409\n",
      "3         3  9.978000     '3'     0.855655\n",
      "4         4  6.982027     '3'     0.401307\n"
     ]
    }
   ],
   "source": [
    "new_df['Strings']=new_df['Strings'].apply(lambda x: f\"'{x}'\")\n",
    "print(new_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## now back to type casting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integers         int32\n",
      "Floats         float64\n",
      "Strings         object\n",
      "More Floats    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# lets check type again\n",
    "\n",
    "print(new_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integers         int32\n",
      "Floats         float64\n",
      "Strings          int32\n",
      "More Floats    float64\n",
      "dtype: object\n",
      "   Integers    Floats  Strings  More Floats\n",
      "0         3  4.869829        4     0.923095\n",
      "1         0  4.049693        3     0.396781\n",
      "2         1  2.903451        2     0.671409\n",
      "3         3  9.978000        3     0.855655\n",
      "4         4  6.982027        3     0.401307\n"
     ]
    }
   ],
   "source": [
    "new_df['Strings'] = new_df['Strings'].str.replace(\"'\", \"\")\n",
    "new_df['Strings']=new_df['Strings'].astype(int)\n",
    "\n",
    "print(new_df.dtypes)\n",
    "print(new_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extracting random sample out of large data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for this example lets go back to the world population data that we got from online csv earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv = pd.read_csv('https://raw.githubusercontent.com/plotly/datasets/master/gapminderDataFiveYear.csv')\n",
    "\n",
    "print(df_csv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample 1% of the rows from the DataFrame\n",
    "one_percent_df_csv = df_csv.sample(frac=0.01)\n",
    "print(one_percent_df_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "doing it for columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample 50% of the columns randomly\n",
    "fifty_percent_columns_df_csv = df_csv.sample(frac=0.5, axis=1).head()\n",
    "print(fifty_percent_columns_df_csv)\n",
    "# AXIS OF NUMPY VS PANDAS ....................."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAVING TO DIFFERENT FILES , EXPORTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to csv\n",
    "df_ai.to_csv('aap_ka_data_csv_main.csv')\n",
    "\n",
    "#to excel\n",
    "df_ai.to_excel('aap_ka_data_excel_main.xlsx',engine='openpyxl')\n",
    "\n",
    "#to json\n",
    "df_ai.to_json('aap_ka_data_json_main.json')\n",
    "\n",
    "#to html\n",
    "df_ai.to_html('aap_ka_data_html_main.html')\n",
    "\n",
    "#data frame to pdf , different ways to do it ,\n",
    "#  we may have home task on assignment on this\n",
    "\n",
    "#to sql\n",
    "#to pickle\n",
    "#to Parquet\n",
    "#to Feather\n",
    "#to ORC\n",
    "#to XML\n",
    "#to SAS\n",
    "#to Stata\n",
    "#to Text\n",
    "#to XLSX\n",
    "#to XLS\n",
    "#to JSON\n",
    "#to HTML\n",
    "#to SQL\n",
    "#to Pickle\n",
    "#to Parquet\n",
    "#to Feather\n",
    "#to ORC\n",
    "#to XML\n",
    "#to Text\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## getting rid of columns or rows in data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a dictionary with emotional data\n",
    "emotions_data = {\n",
    "    'Name': ['Aisha', 'Fatima', 'Zainab', 'Amir', 'Omar', \n",
    "             'Ali', 'Hassan', 'Layla', 'Sara', 'Bilal'],\n",
    "    'Happiness': [8, 6, 7, 5, 9, 4, 6, 8, 5, 7],\n",
    "    'Sadness': [2, 4, 3, 5, 1, 6, 4, 2, 5, 3],\n",
    "    'Anger': [1, 3, 2, 4, 2, 5, 3, 1, 2, 4],\n",
    "    'Fear': [3, 5, 4, 2, 6, 3, 4, 5, 2, 3],\n",
    "    'Surprise': [6, 8, 7, 5, 9, 4, 6, 7, 8, 5],\n",
    "    'Disgust': [2, 1, 3, 4, 2, 3, 1, 2, 4, 3],\n",
    "    'Love': [9, 7, 8, 6, 10, 5, 7, 9, 6, 8]\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the dictionary\n",
    "emotions_df = pd.DataFrame(emotions_data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(emotions_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get rid of column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions_df.drop('Disgust', axis=1, inplace=True) # what if we dont specify inplace = true \n",
    "print(emotions_df)\n",
    "\n",
    "# 21 octuber 2024 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get rid of row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_em = emotions_df.drop(7)\n",
    "print(new_em)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "droping range of rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows from index 0 to 2 (exclusive)\n",
    "new_em.drop(new_em.index[0:2], inplace=True)\n",
    "print(new_em)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reseting index as it is out of order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_em.reset_index(drop=True, inplace=True)\n",
    "# drop=True ?\n",
    "print(new_em)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## joining data frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The append() method in pandas was traditionally used to add rows from one DataFrame to another. However, it has been deprecated since version 1.4.0, and users are encouraged to use concat() instead for better performance and flexibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first creating 3 data frames \n",
    "\n",
    "# DataFrame 1: Clothing Items\n",
    "data1 = {\n",
    "    'ItemID': [1, 2, 3],\n",
    "    'ItemName': ['Abaya', 'Hijab', 'Jilbab'],\n",
    "    'DesignerID': [101, 102, 101]\n",
    "}\n",
    "\n",
    "df_cloth1 = pd.DataFrame(data1)\n",
    "\n",
    "# DataFrame 2: Designers\n",
    "data2 = {\n",
    "    'DesignerID': [101, 102],\n",
    "    'DesignerName': ['Designer A', 'Designer B']\n",
    "}\n",
    "\n",
    "df_cloth2 = pd.DataFrame(data2)\n",
    "\n",
    "# DataFrame 3: Clothing Items\n",
    "data3 = {\n",
    "    'ItemID': [4, 5],\n",
    "    'ItemName': ['Kaftan', 'Tunic'],\n",
    "    'DesignerID': [103, 104]\n",
    "}\n",
    "\n",
    "df_cloth3 = pd.DataFrame(data3)\n",
    "\n",
    "\n",
    "print(\"DataFrame clothes 1:\\n\", df_cloth1)\n",
    "print(\"\\nDataFrame clothes 2:\\n\", df_cloth2)\n",
    "print(\"\\nDataFrame clothes 3:\\n\", df_cloth3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge on DesignerID , merging based on a common column\n",
    "merged_df = df_cloth1.merge(df_cloth2, on='DesignerID')\n",
    "print(\"\\nMerged DataFrame:\\n\", merged_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what if multiple common columns using merge, # home task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vertically stacking data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate both DataFrames vertically\n",
    "concat_df = pd.concat([df_cloth1, df_cloth3], ignore_index=True)\n",
    "print(\"\\nConcatenated DataFrame:\\n\", concat_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate both DataFrames horizontal\n",
    "concat_df2 = pd.concat([df_cloth1, df_cloth3], axis=1)\n",
    "print(\"\\nConcatenated DataFrame:\\n\", concat_df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "above is just garbage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate with keys to create a MultiIndex\n",
    "concat_multiindex = pd.concat([df_cloth1, df_cloth3], keys=['Modest_Clothing', 'Medieval_Clothing'])\n",
    "print(\"\\nConcatenated DataFrame with MultiIndex:\\n\", concat_multiindex)\n",
    "# can we do multiindexing in single data frame ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"border:2px dashed red; border-radius:15px; font-family: 'Bradley Hand', cursive;background-color:white;color:red;font-size:200%\">What could be the use case for above example ?🌌</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering / Searching Data in Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             pai_name  pai_cgpa  pai_oop\n",
      "0       Ahmed Lashari      3.10        A\n",
      "1        Nashwa Rahim      3.46        A\n",
      "2        Faakhir Abid      2.99       A-\n",
      "3     Muhammad Haseeb      3.42       A-\n",
      "4     Munazzah Fatima      2.95  pending\n",
      "5         Shoaib Khan      2.62  pending\n",
      "6        Hussain Shah      2.38       B-\n",
      "7         Hassan Shah      2.44       B-\n",
      "8       Umama Taimoor      3.51  pending\n",
      "9        Muskan Nasir      2.33  pending\n",
      "10     Muhammad Osama      1.29        -\n",
      "11       Fatiqa Munir      2.08  pending\n",
      "12        Yawar Lodhi      1.94        C\n",
      "13         Sayil Raza      1.91       D+\n",
      "14        Daniyal Ali      1.60        -\n",
      "15        Fatima Khan      3.43       A-\n",
      "16           Eman Ali      2.64  pending\n",
      "17      Haider Sheikh      1.20        -\n",
      "18       Shaheer Khan      2.31  pending\n",
      "19     Ismail Mohmand      3.44       A+\n",
      "20        Mohid Zahid      1.54        -\n",
      "21         Naeem Khan      2.74       B-\n",
      "22      Jibran Khalil      2.52        A\n",
      "23          Mujeeb Ur      2.86  pending\n",
      "24     Usama Sikandar      2.56  pending\n",
      "25      Rayan Hussain      2.28       C+\n",
      "26     Muhammad Awais      1.61        -\n",
      "27       Hamza Sajjad      2.13       C-\n",
      "28          Arsam Ali      3.10       C+\n",
      "29    Muhammad Tayyab      2.52  pending\n",
      "30          Aamir Ali      1.25        -\n",
      "31         Hamid Khan      1.56        -\n",
      "32     Muhammad Abbas      2.05  pending\n",
      "33          Ali Irfan      2.15  pending\n",
      "34        Maryam Amin      2.05       C+\n",
      "35       Sohail Ahmad      2.43  pending\n",
      "36  Muhammad Abdullah      1.97        -\n",
      "37      Mehtab Hashmi      1.34  pending\n",
      "38     Ghulam Murtaza      2.07        D\n",
      "39        Bilal Ahmad      3.29       B-\n",
      "40            Saif Ur      2.73  pending\n",
      "41             Raqeeb      3.51        A\n",
      "42          Ahmad Jan      2.32        B\n",
      "43          Asaf Khan      3.34       B+\n",
      "44       Talha Zaheer      0.00  pending\n"
     ]
    }
   ],
   "source": [
    "print(df_ai)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we are interested to get unique gpa values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_ai.pai_cgpa.unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "getting count of unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_ai.pai_cgpa.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## checking if it exists in a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_ai['pai_name']=='Ahmed Lashari')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If it exists show me record\n",
    "print(df_ai.query(\"pai_name == 'Nashwa Rahim'\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show records of students that contain letter r\n",
    "print(df_ai.query(\"pai_name.str.contains('r', case=False)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         pai_name  pai_cgpa  pai_oop\n",
      "12    Yawar Lodhi      1.94        C\n",
      "13     Sayil Raza      1.91       D+\n",
      "17  Haider Sheikh      1.20        -\n",
      "30      Aamir Ali      1.25        -\n",
      "44   Talha Zaheer      0.00  pending\n"
     ]
    }
   ],
   "source": [
    "# getting records of studetns who name contains letter r and have cgpa less than 2\n",
    "mytemp = df_ai.pai_name.str.contains('r', case=False) & (df_ai.pai_cgpa <2)\n",
    "#print(mytemp)  it will return boolean mask\n",
    "print(df_ai[mytemp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             pai_name  pai_cgpa  pai_oop\n",
      "6        Hussain Shah      2.38       B-\n",
      "7         Hassan Shah      2.44       B-\n",
      "8       Umama Taimoor      3.51  pending\n",
      "9        Muskan Nasir      2.33  pending\n",
      "10     Muhammad Osama      1.29        -\n",
      "11       Fatiqa Munir      2.08  pending\n",
      "12        Yawar Lodhi      1.94        C\n",
      "13         Sayil Raza      1.91       D+\n",
      "14        Daniyal Ali      1.60        -\n",
      "17      Haider Sheikh      1.20        -\n",
      "18       Shaheer Khan      2.31  pending\n",
      "20        Mohid Zahid      1.54        -\n",
      "25      Rayan Hussain      2.28       C+\n",
      "26     Muhammad Awais      1.61        -\n",
      "27       Hamza Sajjad      2.13       C-\n",
      "30          Aamir Ali      1.25        -\n",
      "31         Hamid Khan      1.56        -\n",
      "32     Muhammad Abbas      2.05  pending\n",
      "33          Ali Irfan      2.15  pending\n",
      "34        Maryam Amin      2.05       C+\n",
      "35       Sohail Ahmad      2.43  pending\n",
      "36  Muhammad Abdullah      1.97        -\n",
      "37      Mehtab Hashmi      1.34  pending\n",
      "38     Ghulam Murtaza      2.07        D\n",
      "41             Raqeeb      3.51        A\n",
      "42          Ahmad Jan      2.32        B\n",
      "44       Talha Zaheer      0.00  pending\n"
     ]
    }
   ],
   "source": [
    "#tell me names of students whose gpa is greater than 3.5 or less than 2.5\n",
    "\n",
    "# getting records of studetns who name contains letter r and have cgpa less than 2\n",
    "mytemp2 = (df_ai.pai_cgpa <2.5) | (df_ai.pai_cgpa >3.5)\n",
    "#print(mytemp)  it will return boolean mask\n",
    "print(df_ai[mytemp2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_ai.pai_oop.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "by looking at above out , tell me what is going on here ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_ai.pai_oop.value_counts().nsmallest(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_ai.pai_oop.value_counts().nlargest(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:aqua\">home task :how    isin        works in data frame</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### breaking your names into seperate columns as first name and last name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             pai_name  pai_cgpa  pai_oop First_Name Last Name\n",
      "0       Ahmed Lashari      3.10        A      Ahmed   Lashari\n",
      "1        Nashwa Rahim      3.46        A     Nashwa     Rahim\n",
      "2        Faakhir Abid      2.99       A-    Faakhir      Abid\n",
      "3     Muhammad Haseeb      3.42       A-   Muhammad    Haseeb\n",
      "4     Munazzah Fatima      2.95  pending   Munazzah    Fatima\n",
      "5         Shoaib Khan      2.62  pending     Shoaib      Khan\n",
      "6        Hussain Shah      2.38       B-    Hussain      Shah\n",
      "7         Hassan Shah      2.44       B-     Hassan      Shah\n",
      "8       Umama Taimoor      3.51  pending      Umama   Taimoor\n",
      "9        Muskan Nasir      2.33  pending     Muskan     Nasir\n",
      "10     Muhammad Osama      1.29        -   Muhammad     Osama\n",
      "11       Fatiqa Munir      2.08  pending     Fatiqa     Munir\n",
      "12        Yawar Lodhi      1.94        C      Yawar     Lodhi\n",
      "13         Sayil Raza      1.91       D+      Sayil      Raza\n",
      "14        Daniyal Ali      1.60        -    Daniyal       Ali\n",
      "15        Fatima Khan      3.43       A-     Fatima      Khan\n",
      "16           Eman Ali      2.64  pending       Eman       Ali\n",
      "17      Haider Sheikh      1.20        -     Haider    Sheikh\n",
      "18       Shaheer Khan      2.31  pending    Shaheer      Khan\n",
      "19     Ismail Mohmand      3.44       A+     Ismail   Mohmand\n",
      "20        Mohid Zahid      1.54        -      Mohid     Zahid\n",
      "21         Naeem Khan      2.74       B-      Naeem      Khan\n",
      "22      Jibran Khalil      2.52        A     Jibran    Khalil\n",
      "23          Mujeeb Ur      2.86  pending     Mujeeb        Ur\n",
      "24     Usama Sikandar      2.56  pending      Usama  Sikandar\n",
      "25      Rayan Hussain      2.28       C+      Rayan   Hussain\n",
      "26     Muhammad Awais      1.61        -   Muhammad     Awais\n",
      "27       Hamza Sajjad      2.13       C-      Hamza    Sajjad\n",
      "28          Arsam Ali      3.10       C+      Arsam       Ali\n",
      "29    Muhammad Tayyab      2.52  pending   Muhammad    Tayyab\n",
      "30          Aamir Ali      1.25        -      Aamir       Ali\n",
      "31         Hamid Khan      1.56        -      Hamid      Khan\n",
      "32     Muhammad Abbas      2.05  pending   Muhammad     Abbas\n",
      "33          Ali Irfan      2.15  pending        Ali     Irfan\n",
      "34        Maryam Amin      2.05       C+     Maryam      Amin\n",
      "35       Sohail Ahmad      2.43  pending     Sohail     Ahmad\n",
      "36  Muhammad Abdullah      1.97        -   Muhammad  Abdullah\n",
      "37      Mehtab Hashmi      1.34  pending     Mehtab    Hashmi\n",
      "38     Ghulam Murtaza      2.07        D     Ghulam   Murtaza\n",
      "39        Bilal Ahmad      3.29       B-      Bilal     Ahmad\n",
      "40            Saif Ur      2.73  pending       Saif        Ur\n",
      "41             Raqeeb      3.51        A     Raqeeb      None\n",
      "42          Ahmad Jan      2.32        B      Ahmad       Jan\n",
      "43          Asaf Khan      3.34       B+       Asaf      Khan\n",
      "44       Talha Zaheer      0.00  pending      Talha    Zaheer\n"
     ]
    }
   ],
   "source": [
    "#   'pai_name' column into 'First Name' and 'Last_Name'\n",
    "df_ai[['First_Name', 'Last Name']] = df_ai['pai_name'].str.split(' ',expand=True)\n",
    "\n",
    "\n",
    "print(df_ai)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## randomly assign values from a list to rows in data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             pai_name  pai_cgpa  pai_oop First_Name Last Name      City\n",
      "0       Ahmed Lashari      3.10        A      Ahmed   Lashari    Quetta\n",
      "1        Nashwa Rahim      3.46        A     Nashwa     Rahim    Quetta\n",
      "2        Faakhir Abid      2.99       A-    Faakhir      Abid  Peshawar\n",
      "3     Muhammad Haseeb      3.42       A-   Muhammad    Haseeb  Peshawar\n",
      "4     Munazzah Fatima      2.95  pending   Munazzah    Fatima    Quetta\n",
      "5         Shoaib Khan      2.62  pending     Shoaib      Khan    Lahore\n",
      "6        Hussain Shah      2.38       B-    Hussain      Shah    Lahore\n",
      "7         Hassan Shah      2.44       B-     Hassan      Shah    Lahore\n",
      "8       Umama Taimoor      3.51  pending      Umama   Taimoor    Lahore\n",
      "9        Muskan Nasir      2.33  pending     Muskan     Nasir   Karachi\n",
      "10     Muhammad Osama      1.29        -   Muhammad     Osama    Lahore\n",
      "11       Fatiqa Munir      2.08  pending     Fatiqa     Munir    Lahore\n",
      "12        Yawar Lodhi      1.94        C      Yawar     Lodhi    Lahore\n",
      "13         Sayil Raza      1.91       D+      Sayil      Raza   Karachi\n",
      "14        Daniyal Ali      1.60        -    Daniyal       Ali    Lahore\n",
      "15        Fatima Khan      3.43       A-     Fatima      Khan    Lahore\n",
      "16           Eman Ali      2.64  pending       Eman       Ali   Karachi\n",
      "17      Haider Sheikh      1.20        -     Haider    Sheikh    Lahore\n",
      "18       Shaheer Khan      2.31  pending    Shaheer      Khan  Peshawar\n",
      "19     Ismail Mohmand      3.44       A+     Ismail   Mohmand   Karachi\n",
      "20        Mohid Zahid      1.54        -      Mohid     Zahid    Lahore\n",
      "21         Naeem Khan      2.74       B-      Naeem      Khan    Lahore\n",
      "22      Jibran Khalil      2.52        A     Jibran    Khalil  Peshawar\n",
      "23          Mujeeb Ur      2.86  pending     Mujeeb        Ur    Lahore\n",
      "24     Usama Sikandar      2.56  pending      Usama  Sikandar   Karachi\n",
      "25      Rayan Hussain      2.28       C+      Rayan   Hussain    Quetta\n",
      "26     Muhammad Awais      1.61        -   Muhammad     Awais    Lahore\n",
      "27       Hamza Sajjad      2.13       C-      Hamza    Sajjad  Peshawar\n",
      "28          Arsam Ali      3.10       C+      Arsam       Ali    Quetta\n",
      "29    Muhammad Tayyab      2.52  pending   Muhammad    Tayyab   Karachi\n",
      "30          Aamir Ali      1.25        -      Aamir       Ali  Peshawar\n",
      "31         Hamid Khan      1.56        -      Hamid      Khan    Quetta\n",
      "32     Muhammad Abbas      2.05  pending   Muhammad     Abbas    Lahore\n",
      "33          Ali Irfan      2.15  pending        Ali     Irfan    Quetta\n",
      "34        Maryam Amin      2.05       C+     Maryam      Amin   Karachi\n",
      "35       Sohail Ahmad      2.43  pending     Sohail     Ahmad    Lahore\n",
      "36  Muhammad Abdullah      1.97        -   Muhammad  Abdullah    Quetta\n",
      "37      Mehtab Hashmi      1.34  pending     Mehtab    Hashmi   Karachi\n",
      "38     Ghulam Murtaza      2.07        D     Ghulam   Murtaza   Karachi\n",
      "39        Bilal Ahmad      3.29       B-      Bilal     Ahmad  Peshawar\n",
      "40            Saif Ur      2.73  pending       Saif        Ur    Quetta\n",
      "41             Raqeeb      3.51        A     Raqeeb      None    Quetta\n",
      "42          Ahmad Jan      2.32        B      Ahmad       Jan   Karachi\n",
      "43          Asaf Khan      3.34       B+       Asaf      Khan  Peshawar\n",
      "44       Talha Zaheer      0.00  pending      Talha    Zaheer  Peshawar\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cities=['Peshawar','Lahore','Karachi','Quetta']\n",
    "\n",
    "df_ai['City'] = np.random.choice(cities, len(df_ai))\n",
    "\n",
    "print(df_ai)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get records of people of Karachi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pai_name</th>\n",
       "      <th>pai_cgpa</th>\n",
       "      <th>pai_oop</th>\n",
       "      <th>First_Name</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>City</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Muskan Nasir</td>\n",
       "      <td>2.33</td>\n",
       "      <td>pending</td>\n",
       "      <td>Muskan</td>\n",
       "      <td>Nasir</td>\n",
       "      <td>Karachi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Sayil Raza</td>\n",
       "      <td>1.91</td>\n",
       "      <td>D+</td>\n",
       "      <td>Sayil</td>\n",
       "      <td>Raza</td>\n",
       "      <td>Karachi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Eman Ali</td>\n",
       "      <td>2.64</td>\n",
       "      <td>pending</td>\n",
       "      <td>Eman</td>\n",
       "      <td>Ali</td>\n",
       "      <td>Karachi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Ismail Mohmand</td>\n",
       "      <td>3.44</td>\n",
       "      <td>A+</td>\n",
       "      <td>Ismail</td>\n",
       "      <td>Mohmand</td>\n",
       "      <td>Karachi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Usama Sikandar</td>\n",
       "      <td>2.56</td>\n",
       "      <td>pending</td>\n",
       "      <td>Usama</td>\n",
       "      <td>Sikandar</td>\n",
       "      <td>Karachi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Muhammad Tayyab</td>\n",
       "      <td>2.52</td>\n",
       "      <td>pending</td>\n",
       "      <td>Muhammad</td>\n",
       "      <td>Tayyab</td>\n",
       "      <td>Karachi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Maryam Amin</td>\n",
       "      <td>2.05</td>\n",
       "      <td>C+</td>\n",
       "      <td>Maryam</td>\n",
       "      <td>Amin</td>\n",
       "      <td>Karachi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Mehtab Hashmi</td>\n",
       "      <td>1.34</td>\n",
       "      <td>pending</td>\n",
       "      <td>Mehtab</td>\n",
       "      <td>Hashmi</td>\n",
       "      <td>Karachi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Ghulam Murtaza</td>\n",
       "      <td>2.07</td>\n",
       "      <td>D</td>\n",
       "      <td>Ghulam</td>\n",
       "      <td>Murtaza</td>\n",
       "      <td>Karachi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Ahmad Jan</td>\n",
       "      <td>2.32</td>\n",
       "      <td>B</td>\n",
       "      <td>Ahmad</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Karachi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pai_name  pai_cgpa  pai_oop First_Name Last Name     City\n",
       "9      Muskan Nasir      2.33  pending     Muskan     Nasir  Karachi\n",
       "13       Sayil Raza      1.91       D+      Sayil      Raza  Karachi\n",
       "16         Eman Ali      2.64  pending       Eman       Ali  Karachi\n",
       "19   Ismail Mohmand      3.44       A+     Ismail   Mohmand  Karachi\n",
       "24   Usama Sikandar      2.56  pending      Usama  Sikandar  Karachi\n",
       "29  Muhammad Tayyab      2.52  pending   Muhammad    Tayyab  Karachi\n",
       "34      Maryam Amin      2.05       C+     Maryam      Amin  Karachi\n",
       "37    Mehtab Hashmi      1.34  pending     Mehtab    Hashmi  Karachi\n",
       "38   Ghulam Murtaza      2.07        D     Ghulam   Murtaza  Karachi\n",
       "42        Ahmad Jan      2.32        B      Ahmad       Jan  Karachi"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ai[df_ai.City=='Karachi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ai.groupby(['City','pai_oop']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many cities are there\n",
    "len(df_ai.groupby('City'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## show me records whose gpa is less than average gpa of class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ai[df_ai.pai_cgpa < df_ai.pai_cgpa.mean()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now who have greater than average of class\n",
    "df_ai[df_ai.pai_cgpa > df_ai.pai_cgpa.mean()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### show only names of students whose gpa is less than average of class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ai[df_ai.pai_cgpa < df_ai.pai_cgpa.mean()]['First_Name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "group by city and show their average gpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ai.groupby('City').pai_cgpa.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## now lets replace numbers in emotional data frame with some textual values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define the bins and labels\n",
    "bins = [0, 3, 6, 9, 10]  # Define the edges of the bins\n",
    "labels = ['low', 'mid', 'above mid', 'high']  # Define the corresponding labels\n",
    "\n",
    "# Use pd.cut to create a new column with labels based on the defined ranges\n",
    "emotions_df['Sadness_Category'] = pd.cut(emotions_df['Sadness'], bins=bins, labels=labels, right=True)\n",
    "\n",
    "emotions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pd.cut: This function is used to categorize continuous numerical data into discrete bins (or ranges).<br>\n",
    "bins=bins: The bins parameter defines the edges of the ranges you want to create. For example, if bins = [0, 3, 6, 10], it creates intervals like:<br>\n",
    "(0, 3]<br>\n",
    "(3, 6]<br>\n",
    "(6, 10]<br>\n",
    "labels=labels: This parameter assigns names to each bin. For example, if labels = ['low', 'medium', 'high'], then:<br>\n",
    "Values in (0, 3] will be labeled as \"low\".<br>\n",
    "Values in (3, 6] will be labeled as \"medium\".<br>\n",
    "Values in (6, 10] will be labeled as \"high\".<br>\n",
    "right=True: This means that the right edge of each bin is included in that bin. So, if a value is exactly equal to the right edge (like 3), it will be categorized into that bin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " changing textual data to numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample DataFrame in Urdu\n",
    "ddata = {\n",
    "    'نام': ['عائشہ', 'فاطمہ', 'زینب', 'امیر', 'عمر', 'علی', 'حسن', 'لیلیٰ', 'سارہ', 'بلال'],\n",
    "    'احساسات': ['مثبت', 'منفی', 'نیوٹرل', 'مثبت', 'مثبت', 'نیوٹرل', 'مثبت', 'منفی', 'مثبت', 'نیوٹرل']\n",
    "}\n",
    "\n",
    "\n",
    "urdu_emotions_df = pd.DataFrame(ddata)\n",
    "urdu_emotions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urdu_emotions_df['احساسات'] = urdu_emotions_df['احساسات'].replace({'مثبت': 1, 'نیوٹرل': 0, 'منفی': -1})\n",
    "urdu_emotions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using another way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "your_data = {\n",
    "    'Name': [\n",
    "        'Ahmed Lashari', 'Nashwa Rahim', 'Faakhir Abid', 'Muhammad Haseeb',\n",
    "        'Munazzah Fatima', 'Shoaib Khan', 'Hussain Shah', 'Hassan Shah',\n",
    "        'Umama Taimoor', 'Muskan Nasir', 'Muhammad Osama', 'Fatiqa Munir',\n",
    "        'Yawar Lodhi', 'Sayil Raza', 'Daniyal Ali', 'Fatima Khan',\n",
    "        'Eman Ali', 'Haider Sheikh', 'Shaheer Khan', 'Ismail Mohmand',\n",
    "        'Mohid Zahid', 'Naeem Khan', 'Jibran Khalil', 'Mujeeb Ur',\n",
    "        'Usama Sikandar', 'Rayan Hussain', 'Muhammad Awais', 'Hamza Sajjad',\n",
    "        'Arsam Ali', 'Muhammad Tayyab', 'Aamir Ali', 'Hamid Khan',\n",
    "        'Muhammad Abbas', 'Ali Irfan', 'Maryam Amin', 'Sohail Ahmad',\n",
    "        'Muhammad Abdullah', 'Mehtab Hashmi', 'Ghulam Murtaza',\n",
    "        'Bilal Ahmad', 'Saif Ur', 'Raqeeb', 'Ahmad Jan',\n",
    "        'Asaf Khan', 'Talha Zaheer'\n",
    "    ],\n",
    "    'Gender': [\n",
    "        'Male', 'Female', 'Male', 'Male',\n",
    "        'Female', 'Male', 'Male', 'Male',\n",
    "        'Female', 'Female', 'Male', 'Female',\n",
    "        'Male', 'Male', 'Male', 'Female',\n",
    "        'Female', 'Male', 'Male', 'Male',\n",
    "        'Male', 'Male',  'Male','Male',\n",
    "        'Male','Male','Male','Male',\n",
    "        'Male','Male','Male','Male',\n",
    "        'Male','Male','Female','Male',\n",
    "        'Male','Male','Male',\n",
    "        'Male','Male','Male','Male',\n",
    "        'Male','Male'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Creating the DataFrame\n",
    "names_df = pd.DataFrame(your_data)\n",
    "names_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "#names_df['gender_innumber']=names_df.Gender.factorize() gives error becuause \n",
    "# factorize method returns two things\n",
    "names_df['gender_innumber']=names_df.Gender.factorize()[0]  # just give 0,1 values not unique categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_df.sort_values(by='Name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## melting data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_data = {\n",
    "    'Name': ['Cat', 'Dog', 'Rabbit'],\n",
    "    'cuteness': [70, 50, 90],\n",
    "    'permission': [100, 40, 70]\n",
    "}\n",
    "pet_df = pd.DataFrame(example_data)\n",
    "pet_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "id_vars=['Name']:\n",
    "This parameter specifies which column(s) should remain as identifier variables in the melted DataFrame. In this case, the \"Name\" column will be kept as is, while other columns will be transformed into rows.\n",
    "\n",
    "var_name='cuteness_permission':\n",
    "This parameter allows you to specify the name of the new column that will contain the names of the original columns that are being melted (unpivoted). Here, it is named \"cuteness_permission\".\n",
    "\n",
    "value_name='numeric_data':\n",
    "This parameter specifies the name of the new column that will contain the values from the melted columns. In this case, it is named \"numeric_data\".\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_df = pd.melt(pet_df, id_vars=['Name'], var_name='cuteness_permission', value_name='numeric_data')\n",
    "melted_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose of Melting DataFrames<br>\n",
    "Melting a DataFrame serves several important purposes:<br>\n",
    "Reshaping Data: It transforms wide-format data (where multiple columns represent different variables) into long-format data (where each variable is represented in a single column). This can make it easier to analyze and visualize data.<br>\n",
    "Facilitating Analysis: Long-format data is often more suitable for certain types of analysis and visualizations, especially when using libraries like seaborn or matplotlib, which prefer data in this format.<br>\n",
    "Simplifying Aggregation: When data is in long format, it becomes easier to group by certain variables and perform aggregations or calculations.<br>\n",
    "Improving Compatibility: Some machine learning algorithms and statistical models require data in long format for proper functioning.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_try_try = pd.read_excel('ai_batch_23.xlsx')\n",
    "df_try_try"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivot vs. Melt in Pandas\n",
    "Pivot and melt are two important functions in pandas used for reshaping DataFrames, but they serve opposite purposes. Here's a detailed comparison:\n",
    "1. Pivot\n",
    "Purpose: The pivot() function is used to reshape data from a long format to a wide format. It transforms unique values from one column into separate columns in the resulting DataFrame.\n",
    "Functionality:\n",
    "Parameters:\n",
    "index: Column(s) to use as the new index (row labels).\n",
    "columns: Column(s) to use as the new columns (column labels).\n",
    "values: Column(s) to fill in the values of the new DataFrame.\n",
    "Example:\n",
    "python\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>City</th>\n",
       "      <th>Temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>New York</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-02</td>\n",
       "      <td>New York</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date         City  Temperature\n",
       "0  2021-01-01     New York           30\n",
       "1  2021-01-01  Los Angeles           70\n",
       "2  2021-01-02     New York           32"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Sample DataFrame\n",
    "data2 = {\n",
    "    'Date': ['2021-01-01', '2021-01-01', '2021-01-02'],\n",
    "    'City': ['New York', 'Los Angeles', 'New York'],\n",
    "    'Temperature': [30, 70, 32]\n",
    "}\n",
    "df_x = pd.DataFrame(data2)\n",
    "df_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>City</th>\n",
       "      <th>Los Angeles</th>\n",
       "      <th>New York</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-01-01</th>\n",
       "      <td>70.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-02</th>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "City        Los Angeles  New York\n",
       "Date                             \n",
       "2021-01-01         70.0      30.0\n",
       "2021-01-02          NaN      32.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pivoting the DataFrame\n",
    "pivoted_df = df_x.pivot(index='Date', columns='City', values='Temperature')\n",
    "pivoted_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Melt<br>\n",
    "Purpose: The melt() function is used to transform data from a wide format to a long format. It unpivots or reshapes the DataFrame so that one or more columns are identifier variables, while all other columns are transformed into row entries.\n",
    "Functionality:\n",
    "Parameters:\n",
    "id_vars: Column(s) to keep as identifier variables.\n",
    "value_vars: Column(s) to unpivot (if not specified, all columns not in id_vars will be used).\n",
    "var_name: Name for the new column that will contain the former column names.\n",
    "value_name: Name for the new column that will contain the values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature\tPivot\tMelt\n",
    "Purpose\tReshape data from long to wide format\tReshape data from wide to long format\n",
    "Functionality\tConverts unique values into columns\tUnpivots columns into rows\n",
    "Parameters\tRequires index, columns, and values\tRequires id_vars, value_vars, var_name, and value_name\n",
    "Use Case\tWhen you want to summarize data\tWhen you want to analyze or visualize data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
